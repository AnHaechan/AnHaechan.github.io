<!DOCTYPE html>

<html>
    <head>
        <meta charset="utf-8">
        <title> CV : Haechan An </title>
        <link rel="stylesheet" href="index.css">
    </head>

    <body>
        <header>
            <h1> Haechan An </h1>
        </header>

        <!--
        <nav>

        </nav>
        -->

        <main>
	    <p>
		    <img src="./img/haechan_25.jpg" width="10%"/>
	    </p>
            <p>
		    I'm pursuing a master's degree at graduate school of computing of KAIST, under the advisement of
		    <a href = "https://cp.kaist.ac.kr/jeehoon.kang/"> Prof. Jeehoon Kang, at KAIST Concurrency & Parallelsim Lab</a>. </br>
                My interests are: systems programming, compilers, machine learning and programming languages.</br>
                I want to build a compiler, runtime and programming model that fill the gap between large AI models and heterogenous hardwares. 
                <br>

                <br>
            </p>
            <p>
                <h3> Contact </h3>
                    <ul>
                        <li> Email : haechan.an_at_kaist.ac.kr </li>
                        <li> Github : AnHaechan </li>
                    </ul>
            </p>
	    <p>
		<h3> Current Research Topic </h3>
		<p>
            <h4>AI compilers for distributed & heterogeneous accelerators</h4>
		    Deep learning models, such as generative AI, are increasingly demanding more computation, memory and bandwidth.
	  		</br>
		    To efficiently handle those resource demands, (1) various specialized accelerators have been proposed
		    and (2) the model executions are being distributed to multiple hardwares.
			</br>
		    The benefit of using multiple heterogeneous accelerators can only be utilized by a software stack,
		    including specialized compiler and runtime, which bridge the high-level application and low-level hardwares.
			</br>
		    However, currently there are limited compiler support that can automatically generate efficient execution plans
		    for varying models, given multiple different accelerators including NPU(Neural Processing Unit) and PIM(Processing In Memory).
			</br>
		    My research goal is to design such <b>"AI compilers for distributed & heterogeneous accelerators"</b>.
		</p>
	    </p>
            <p>
                <h3> Experiences </h3>
                    <ul>
                        <li> 2021.01-2021.10, Undergraduate Internship, at <a href ="https://plrg.kaist.ac.kr/home">KAIST PLRG</a> </li>
                            : instrumentation of JNI programs for bug-catching using dataflow analysis  </br>
                            : finding Rust type patterns for shared mutable states in TockOS </br>
                        <li> 2022.01-2022.02, Startup, at Bapyak</li>
                            : developing data pipeline and web frontend </br>
                        <li> 2022.03-2022.06, Undergraduate Internship, at <a href ="https://prosys.kaist.ac.kr/">KAIST Prosys Lab</a> </li>
			                : study on static program analysis and program synthesis </br>
                        <li> 2022.07-, Undergraduate Internship & <b>Master's Student</b>, at <a href ="https://cp.kaist.ac.kr/">KAIST Concurrency and Parallelism Lab</a> </li>
			                : <b> worked on serving ML pipelines on NPU & GPU servers, with adpative scheduling (~5 mo) </b> </br>
			                : <b> worked on automatic program verification by a neuro-symbolic approach (~11 mo) </b> </br>
			                : <b> currently working on AI compilers. Especially for optimizing LLM inference on distributed and heterogeneous hardwares, including NPU & PIM. (2024.03-) </b> </br>
			                : participated in SK Hynix's workshop on AiM(Accelerator-in-Memory) theory & practice
                    </ul>
            </p>
            <p>
                <h3> Programming languages / Dev tools </h3>
			    <ul>
                    <li> General purpose: <b>Python (proficient)</b></li>
                    <li> Systems progamming: <b>Rust (proficient), C and C++</b></li>
                    <li> Functional programming: <b>Ocaml</b></li>
                    <li> Interactive theorem proving: <b>Coq</b></li>
                    <li> Machine learning: <b>PyTorch</b> </li>
                    <li> Dev tools: Familar with basic dev tools, including <b> Linux, Git, Docker, ssh and GCP</b>
                </ul>
            </p>
            <p>
                <h3> Publications / Projects </h3>    
                    <ul>
                        <li> [Publication] One paper (contributed as third author) is under revision, on the field of AI inference serving </li>
                        <li> [Project] Submitted a survey report on AI compilers for distributed & heterogenous accelerators (proprietary) </li>
			<li> [Teaching] Created <a href = https://docs.google.com/presentation/d/1RZdV3Z-Q1NEbpU1-qk9C97yE1QvwNLJ9Gc7JLaFLZCw/edit?usp=sharing>a lecture slide for AI compilers, contributing to KAIST CS492: Microarchitecture Design</a> </li>
                        <li> [Project] Currently leading a project on building a NPU-PIM compiler for LLM inferece (national) </li>
			<li> [Publication] Currently participating a project on generalizing the idea of FlashAttention </li>
		            </ul>
            </p>
    <p> <h3> Education </h3> 
    <ul>
        <li> 2018.03-2023.02, KAIST School of Computing (Undergraduate), GPA 4.04/4.3</li>
        <li> 2019.12-2020.01, Yonsei University (Exchange student) </li>
        <li> 2023.03-, KAIST Graduate School of Computing (Masters student)</li>
    </ul>
    </p>
	<p>
		<h3> Teaching experiences </h3>
		<ul>
			<li> TA of <a href = https://github.com/kaist-cp/cs420> CS420: Compiler Design </a>, 2023 Spring </li>
			<li> TA of <a href = https://github.com/kaist-cp/cs220> CS220: Programming Principles </a>, 2023 Fall </li>
		</ul>
    	</p>
  	<p>
		<h3> Honours </h3>
		<ul>
			<li> School of Computing, Dean's List, 2019 Spring </li>
			<li> School of Computing, Department Valedictorian, 2019 Fall </li>
			<li> School of Computing, Dean's List,  2020 Fall </li>
			<li> Graduation from School of Computing with Summa Cum Laude, 2022 Fall </li>
			<li> School of Computing, Excellent TAs, 2023 Spring </li>
			<li> School of Computing, Excellent TAs, 2023 Fall </li>
		</ul>
	</p>
    <p>
        <h3> Advanced courses I've taken </h3> 
	    These are the courses that I've taken so far as major electives, excluding major required and foundational courses (such as Algorithms, Computer Architectures, Operating Systems, etc). </br>
	    I believe this listing can indicate my general interests and knowledge.
            <ul> <b> Programming Languages & Software Engineering </b>
                <li> CS374, Introduction to Human-Computer Interaction </li>
		<li> CS402, Logic for Computer Science </li>
                <li> CS420, Compiler Design </li>
                <li> CS431, Concurrent Programming </li>
                <li> CS448, Introduction to Information Security </li> 
                <li> CS453, Automated Software Testing </li>
                <li> CS520, Theory of Programming Languages </li>
                <li> CS524, Program Anaylsis </li>
                <li> IS593, Program Reasoning </li>
                <li> Software Foundations: Logical Foundations </li>
                <li> Software Foundations: Programming Language Foundations </li>
            </ul>
            <ul> <b> Systems & Architectures </b>
		<li> CS341, Introduction to Computer Networks </li>
                <li> CS411, Systems for AI </li>
                <li> CS420, Compiler Design </li>
                <li> CS431, Concurrent Programming </li>
                <li> CS492A, Virtualization </li>
                <li> CS510, Computer Architecture </li>
                <li> EE595, Parallel Computer Architecture </li>
            </ul>
            <ul> <b> Machine Learning & AI </b>
		<li> MAS350, Elementary Probability Theory </li>
		<li> CS372, Natural Language Processing with Python </li>
		<li> CS376, Machine Learning </li>
                <li> CS470, Introduction to Artificial Intelligence </li>
                <li> Stanford CS224n, Natural Language Processing with Deep Learning </li>
                <li> EE534, Pattern Recognition </li>
		<li> CS564, Data Science Methodology (WIP) </li>
            </ul>
        </p>
        </main>

    <p>
        <h3> Languages </h3>
        <ul>
            <li> Korean (native, CEFR C2) </li>
            <li> English (advanced, ~CEFR C1) </li>
                <ul>
                    <li> Comfortable with communicating at workplace and discussing academic subjects </li>
                    <li> Working to reach the level of fluency </li>
                </ul>
            <li> Japanese (intermediate, ~CEFR B1) </li>
                <ul>
                    <li> Comfortable with daily conversations </li>
                    <li> JLPT N3 (166/180 pts), 2024.08 </li>
                    <li> Doing for fun, might try to get N2 in 2025 </lI>
                </ul>
        </ul>
        <h3> Other interests </h3>
        <ul>
            <li> Traveling around the world </li>
            <li> Learning new languages, culture and history </li>
            <li> Playing football and watching European football (huge fan of FC Barcelona)  </li>
            <li> Researching about how to live a better life </li>
            <li> Occationally drinking beers, or playing video games with friends after work </li>
        </ul> 
    </p>
    
        <footer>

        </footer>
    </body>
</html>
